# @package _global_
defaults:
  - /model: default
  - /task: default
  - /datamodule: default

scheduler: null

loader:
  batch_size: 5

optimizer:
  lr: 6e-4
  weight_decay: 1e-5

trainer:
  devices: auto
  accelerator: cpu
  max_epochs: 1000
  gradient_clip_val: null
  log_every_n_steps: 10
  val_check_interval: 1.  # val every n batches
  limit_val_batches: 10


callbacks:
  model_checkpoint:
    monitor: "val/loss" # name of the logged metric which determines when model is improving
    mode: "max" # can be "max" or "min"
    save_top_k: 1 # save k best models (determined by above metric)
    save_last: True # additionaly always save model from last epoch
    auto_insert_metric_name: False
    verbose: True

  learning_rate_monitor:
    logging_interval: "step"


train_type:
  name: "train"
  saved_model: null
